| 第9-10讲答疑&nbsp;问题列表  |
|--------------|
|如何在代码运行前提前避免过界问题呢|
|现在的方法在实际应用中会不会占用大量内存啊…|
|在构造字到词索引的时候，用字典映射会不会更快一点|
|那种带限制条件的语句，比如红色的鞋子，把的去掉之后就相当于去掉了限制，怎么解决呢|
|为什么最后的时候一些不是关键词的也被高亮了？混乱了？|
|打分机制是否不止应该考虑出现次数，是否还应该考虑查询词是否完整出现？即查询词完整出现的结果比分开出现的结果应该更加匹配。|
|对于多关键词搜索，我觉得可以考虑某个关键词在目前一段时间的总搜索量。比如搜索特朗普vs拜登，在美国大选出结果前是特朗普的新闻更多(出结果前特朗普疯狂加戏)，出结果后是拜登的新闻更多。|
|通过分词位置提取具有完整词语的摘要片段，存在一些提取中的片段中间含标点符号，是否可以结合借鉴思路2把标点符号前/后的少量内容直接剔除？|
|请问老师像网页相关的是否java是主流语言呢，我自己之前有学过python，但python在搜索引擎或者网页这一块是不是有局限？大家推荐学java的比较多|
|问一问关于类似视频推荐系统和网页这边的搜索是不是统一用的相类似的方法，都是通过标签打分这样子，只是运用不同的算法去实现它，实际上思想是不是一样的呢|
|对于网络搜索中一些被和谐的词，是不是也是用停用词进行实现的呢|
|在摘要生成时选取了重复的句子怎么办（上下文有相同或相似的内容一起被选入）|
|目前的highlight函数的代码逻辑比较复杂，此时是否应该将highlight分解重构为多个子函数以减小后续改进和调试的工作量？但子函数过多也可能会导致代码结构松散，应该如何权衡函数的功能丰富度和逻辑复杂度呢？|
|对关键词进行打分时是否需要考虑其他的同义词？匹配同义词一般是预先建立好相应的同义词集合再进行查找吗？有更好的方法吗？|
|"在设计词的权重的时候，感觉名词更加重要，可以设置更大的权重，其次是动词和形容词，最后是助词语气词之类的。<br/>但是有的词在不同场景下的词性不一样，比如“的得地”单独出现是助词，一起出现是名词，“了”一般是语气词，“好了liao”“了解”却是形容词和动词，这种要怎么判定呢"|
|使用jieba cut 生成的迭代器在遍历之后有没有什么办法让指针重新回到开头？|
|老师我觉得从修改的简易程度，也就是您说的可行性来看，按标点来分可能更合理，用split按标点分割一下，然后判断一下长度是否合理，太长了再进一步删减一下，这样不是更好吗|
|图数据库用于搜索有什么优势？|
|python中有可以直接使用的分辨词性的框架吗|
|当搜索关键词中的不重要的词在文章中出现次数比较少时，打分系统直接用除法会增加很大的权重，这是不是也需要考虑进去？|
|能否把停用词也做排序（打分）？比如停用词里有些词是的确没什么意义的 可以加权较低 而有些停用词（比如数字）还是有些意义的 可以给较高的分数。|
|上次课的高亮处理，对搜索词加上空格之后，有的搜索结果整段都高亮了|
|感觉第二种加权打分结果中有太多停用词，是否可以先跳过停用词，再用加权的方式评分。|
|在用词频打分时，为什么不直接去除掉停用词，而是还要根据停用词的词频反比例加权到score中呢？|
|老师，请问论文检索时根据包含关键词论文的时间顺序排序的功能是怎么实现的？|
|这节课涉及到代表性区分性 tf-idf的内容对我来说都是很新的 需要再进一步理解。代表性区分性目前我们只是靠自己人为来分辨（从这节课来看），比如中国这个词在我们的文档中区分性不明显。（提过的看文章和文档集的词频，也会有特例）人为分辨的前提是自己要理解每个词的性质，这在搜索引擎海量数据中应该不能用人为分辨，那具体有什么算法可以用到的吗|
|最后老师讲到的idf，如果分母取得是词文档出现次数，当词在所有文档出现时，这个值取倒数乘以文档数再取log，idf就等于0|
|对文章出现的词的词频进行排序后，排在前面的同时又是属于停用词，对该词不进行计分统计是否有效果|
|去停用词应用在深度网络框架中效果如何？在哪些任务上在深度模型中应用去停用词可以提升性能呢？|
|"1.停用词表在使用中可以根据情况可以动态变化吗<br/>2.代表性和区分性可以再解释一下吗"|
|现在使用分词对文档关键词进行搜索筛选，把停用词之类的不重要的词权重降低，如果搜索内容加上停用词是完整的逻辑，也就是考虑了上下文的关系，这样会不会造成相似度不完整的情况|
|看到停断词的部分中有符号，如果搜索词中出现了符号，摘要应该会很长，是不是在形成摘要的时候把符号视为停断词不进行处理。|
|感觉现在预加载的东西太多了，之前的有cache，还有今天的停用词，内存消耗大，是否考虑优化|
|对于tf-idf那一块的用法不太了解，可以随便改变参数，如果可以自定义的话，那最后的结果岂不是对个人定义的方式依赖性太大，目前有没有公认的好的统计的公式？|
|看到陈老师在微博上经常转发一些高质量的论文，所以想问问，假如我们知道一个项目/课题的研究方向，知道大概要做什么，但是不确定具体做成什么样子，也不确定具体怎么做，这种情况下，在调研阶段应该怎么找到自己需要的文献呢？怎么去搜论文呢？往往会出现用我以为的关键字去搜，搜出来的结果并不理想，十分困扰我。谢谢陈老师的解答！|
|停用词如果是一个词的组成部分怎么办呢？|
|老师每次遇到一个问题都能讲出，第一考虑...第二考虑...这是经验，还是灵活用上自己的知识储备还是有备而来呢？很想学习这种分析能力|
|感觉标题频率和正文频率可以分别处理再加权一下，像“华为“这种科技文档高频词汇在标题中的出现频率很高，可能超过了一般的停用词|
|tf-idf对于正文和标题需要区别对待吗，对于不同位置的内容，tf-idf是不是就不好处理呀。只能通过我们最后score时对相应部分适当加权去处理？|
|在做tf-idf时要如何对标题和正文进行区分呢|
|课上提到文档中词频过高的词没有“区分度”，所以在搜索时应该对这些词“降分”，但是词频高的不是也说明与搜索词条的相关度更高吗，那以词频作为打分选择，是否会造成区分度和相关度的矛盾？|
|tfidf如何处理新词热词呢|
|课上实现的self.df是依据所有文档建立的。我想可不可以用query匹配到的文档子集来建立df。这样感觉才是不同词在特定查询中重要程度的提现。|
|一个词的文档频率越小就一定能体现区分度吗，有没有可能有例外情况呢，比如某个新闻里用了一个很生僻的词导致打分特别高。|
|现在主流搜索引擎结果排序考虑因素包括哪些|
|TFIDF中，TF的部分是关于词频线性的，而IDF则是关于词在文档集中的出现频率非线性的，这否可以理解为该算法其实相对更在乎词频？|
|停用词一般是人工输入的，jieba似乎可以自行添加停用词，是怎么做到的。|
|关于tf-idf：tf-idf好像是一种关于匹配排序的粗排方法，如果要在某个领域（比如我们可是的科技板块）进行搜索的时候，idf应该针对该领域计算特定领域的idf吧..|
|对于一些打错的字词，比如同音字，怎么纠正他们，然后进行正确词的搜索。|
|停用词那里我们是否可以创建多个停用词表【像数字之类的单独一个表，从而使得打分可以更细致|
|有没有现成的库，设置好参数(比如您提到的禁止词，打分权重等)，输入搜索结果自动打分|